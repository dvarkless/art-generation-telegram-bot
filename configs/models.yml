available_models: ["stable-diffusion", "sample-model"]

upscaler:
  upscaling_resize: 2
  upscaler_1: ESRGAN_4x
  upscaler_2: None
  upscaler_2_strength: 0.5 # <= 1
  # other_settings:
  #   gfpgan_visibility: 0,
  #   codeformer_visibility: 0,
  #   codeformer_weight: 0,

stable-diffusion:
  pos: 0
  checkpoint: v1-5-pruned-emaonly.safetensors
  orientation_square: 512x512
  orientation_portrait: 640x448
  orientation_landscape: 448x640
  default_params:
    negative_prompt: nude,naked,
    sampler_name: Euler a
    steps: 25
    enable_hr: False
    denoising_strength: 0.55
    hr_scale: 2
    hr_upscaler: Latent
    restore_faces: False
    cfg_scale: 8
  img2img_params:
    sampler_name: DDIM
  scores:
    creativity: 5
    skill: 2

sample-model:
  pos: 1 # N+1
  checkpoint: pastelmix-better-vae-fp16.safetensors # Checkpoint's full label without commit hash
  orientation_square: 512x512 # Regular square orientation for the model
  orientation_portrait: 640x448 # Regular portrait orientation for the model
  orientation_landscape: 448x640 # Regular landscape orientation for the model
  default_params:
    negative_prompt: nude,naked, # Use negative prompt as a soft filter for generated images
    sampler_name: DDIM # This option and further you should choose like in web GUI
    steps: 20
    enable_hr: False
    denoising_strength: 0.6
    hr_scale: 2
    hr_upscaler: Latent
    restore_faces: False
    cfg_scale: 8
    # setting1: 0 # and so on...
  img2img_params: # Use different params for img2img. You can add other setting too
    sampler_name: DDIM
  scores: # Just decorative numbers
    creativity: 1
    skill: 5

# Add other models here: (put their weights into ./stable-diffusion-webui/models/Stable-diffusion/your-model.safetensors)
